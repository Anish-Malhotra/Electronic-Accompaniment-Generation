{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bass_Model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uRBwWiDSQqaA"},"source":["# **EDM Bass Accompaniment Generation**\n","*by Matthew Avallone, Anish Malhotra*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rMsI7aw0gOti"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UYMJ2dY0v2ob","trusted":true,"colab":{}},"source":["import numpy as np\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FDgdtH7SgRfP"},"source":["# **Loading The Data**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lzwg3hb4eGjG","trusted":true,"colab":{}},"source":["data_folder = '../input/'\n","os.chdir(data_folder)\n","\n","os.listdir(data_folder)\n","\n","X_bass = np.load(data_folder + 'X_bass.npy')\n","y_bass = np.load(data_folder + 'y_bass.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5EhpNzAVhC4C","trusted":true,"colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","Xtr_melody, Xts_melody = train_test_split(X_bass, test_size=0.01, shuffle=False)\n","ytr_bass, yts_bass = train_test_split(y_bass, test_size=0.01, shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"YHkNXhSrwSy-","colab_type":"code","colab":{}},"source":["print(len(Xtr_melody))\n","\n","Xts_melody = Xts_melody[0:32]\n","yts_bass = yts_bass[0:32]\n","\n","print(len(Xts_melody))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wnUqQ9yPwSzF","colab_type":"text"},"source":["Creating a target set, which is output shifted by 1 step"]},{"cell_type":"code","metadata":{"trusted":true,"id":"5kxu1ICvwSzH","colab_type":"code","colab":{}},"source":["Xtr_melody_pad = ytr_bass\n","\n","for i in range(0, len(ytr_bass)):\n","    for j in range(0, len(ytr_bass[i])):\n","        Xtr_melody_pad[i][j] = np.hstack(([0],ytr_bass[i][j][:-1]))\n","\n","print(Xtr_melody_pad.shape)\n","print(Xtr_melody_pad[0].shape)\n","\n","# Xtr_melody_pad = ytr_bass\n","# padding = np.zeros(83)\n","# for i in range(0, len(ytr_bass)):\n","#     for j in range(0, len(ytr_bass[i])):\n","#         Xtr_melody_pad[i] = np.vstack((padding,ytr_bass[i][:-1]))\n","\n","# print(Xtr_melody_pad.shape)\n","# print(Xtr_melody_pad[0].shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"52T2kBEUwSzN","colab_type":"code","colab":{}},"source":["print(Xtr_melody_pad[0][0])\n","print(Xtr_melody_pad[0][65])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KGGCxkjYnkVk"},"source":["# **Model Setup**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Tq-MN5h4nuAY","trusted":true,"colab":{}},"source":["from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","from keras.utils.vis_utils import plot_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8DqK7cspzx4v","trusted":true,"colab":{}},"source":["num_classes = 7\n","note_shift = 24\n","num_of_notes = 83\n","num_measures = 0.25\n","\n","tpqn = 96 # Varies with MIDI file, currently using same resolution\n","\n","n_timesteps= int(4*num_measures*tpqn) # 96 ticks per quarter note x 4 quarter notes per measure x number of measures\n","\n","batchsize = 8\n","\n","# configure\n","num_encoder_tokens = num_of_notes # length of the sequence at each time step = num of notes\n","num_decoder_tokens = num_of_notes\n","latent_dim = 256"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qD6md5bUwSzq","colab_type":"text"},"source":["**Autoencoder Model**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vZD5nprYxdPL","trusted":true,"colab":{}},"source":["# Define an input sequence and process it.\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","autoencoder = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","autoencoder.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"FPGgrgviwS0K","colab_type":"code","colab":{}},"source":["autoencoder.summary()\n","\n","# plot the model and save as image\n","# plot_model(autoencoder, to_file='model.png', show_shapes=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EmPYpYSIwS0Q","colab_type":"text"},"source":["**Encoder Inference Model**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"lilD4NsRwS0R","colab_type":"code","colab":{}},"source":["# define encoder inference model\n","encoder_model = Model(encoder_inputs, encoder_states)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"VOk_ZXUPwS0W","colab_type":"code","colab":{}},"source":["encoder_model.summary()\n","\n","# plot_model(encoder_model, to_file='encoder_model.png', show_shapes=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rX1RN_IpwS0b","colab_type":"text"},"source":["**Decoder Inference Model**"]},{"cell_type":"code","metadata":{"trusted":true,"id":"zt0Tz3gVwS0d","colab_type":"code","colab":{}},"source":["# define decoder inference model\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"rA79fa8dwS0h","colab_type":"code","colab":{}},"source":["decoder_model.summary()\n","\n","# plot_model(decoder_model, to_file='decoder_model.png', show_shapes=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ob0qW7XMxjmu"},"source":["## Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cL71g5kWkGtq","trusted":true,"colab":{}},"source":["hist_bass = autoencoder.fit([Xtr_melody, Xtr_melody_pad], ytr_bass, batch_size=batchsize, epochs=30, verbose=2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_1muwe5UxwL2"},"source":["## Testing\n","\n","Predictions are done using the inferences encoder and decoder models"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yoUWS7-GxyK7","trusted":true,"colab":{}},"source":["# generate target given source sequence\n","def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n","    # encode\n","    state = infenc.predict(source)\n","    \n","    # start of sequence input\n","    target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n","\n","    # collect predictions\n","    output = list()\n","    for t in range(n_steps):\n","        # predict next note\n","        yhat, h, c = infdec.predict([target_seq] + state)\n","        \n","        # store prediction\n","        output.append(yhat[0,0,:])\n","       \n","        # update state\n","        state = [h, c]\n","        \n","        # update target sequence\n","        target_seq = yhat\n","        \n","    return (np.array(output)).reshape(n_steps,cardinality)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g5A7IaaMzU6c","trusted":true,"colab":{}},"source":["test_phrase = np.empty((1,n_timesteps, num_of_notes))\n","ypred_bass = np.empty((yts_bass.shape))\n","\n","for i in range(0, len(Xts_melody)):\n","    test_phrase[0] = Xts_melody[i]\n","    ypred_bass[i] = predict_sequence(encoder_model, decoder_model, test_phrase, n_timesteps, num_of_notes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M_NJg4evmhAu"},"source":["# Saving Results"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ghoc0HJwiXUD","trusted":true,"colab":{}},"source":["# Save the predicted values for post processing\n","os.chdir('../working/')\n","\n","np.save('../working/Xts_bass', Xts_melody)\n","np.save('../working/ypred_bass', ypred_bass)\n","np.save('../working/yts_bass', yts_bass)\n","\n","# Save the model for future use\n","\n","autoencoder.save('../working/bass_model.h5')\n","encoder_model.save('../working/bass_encoder.h5')\n","decoder_model.save('../working/bass_decoder.h5')"],"execution_count":0,"outputs":[]}]}