{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chords_Model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"text","id":"uRBwWiDSQqaA"},"cell_type":"markdown","source":["# **EDM Chords Accompaniment Generation**\n","*by Matthew Avallone, Anish Malhotra*"]},{"metadata":{"colab_type":"text","id":"rMsI7aw0gOti"},"cell_type":"markdown","source":["# Imports"]},{"metadata":{"colab_type":"code","id":"UYMJ2dY0v2ob","trusted":true,"colab":{}},"cell_type":"code","source":["import numpy as np\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"FDgdtH7SgRfP"},"cell_type":"markdown","source":["# **Loading The Data**"]},{"metadata":{"colab_type":"code","id":"lzwg3hb4eGjG","trusted":true,"colab":{}},"cell_type":"code","source":["data_folder = '../input/'\n","os.chdir(data_folder)\n","\n","os.listdir(data_folder)\n","\n","X_chords = np.load(data_folder + 'X_chords.npy')\n","y_chords = np.load(data_folder + 'y_chords.npy')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"5EhpNzAVhC4C","trusted":true,"colab":{}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","Xtr_melody, Xts_melody = train_test_split(X_chords, test_size=0.01, shuffle=False)\n","ytr_chords, yts_chords = train_test_split(y_chords, test_size=0.01, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"O9taHVjJGCfZ","colab_type":"code","colab":{}},"cell_type":"code","source":["print(len(Xtr_melody))\n","\n","Xts_melody = Xts_melody[0:25]\n","yts_chords = yts_chords[0:25]\n","\n","print(len(Xts_melody))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3EWPM2cxGCfc","colab_type":"text"},"cell_type":"markdown","source":["Creating a target set, which is output shifted by 1 step"]},{"metadata":{"trusted":true,"id":"IuUJ-RG_GCfe","colab_type":"code","colab":{}},"cell_type":"code","source":["Xtr_melody_pad = ytr_chords\n","\n","for i in range(0, len(ytr_chords)):\n","    for j in range(0, len(ytr_chords[i])):\n","        Xtr_melody_pad[i][j] = np.hstack(([0],ytr_chords[i][j][:-1]))\n","\n","print(Xtr_melody_pad.shape)\n","print(Xtr_melody_pad[0].shape)\n","\n","# Xtr_melody_pad = ytr_chords\n","# padding = np.zeros(83)\n","# for i in range(0, len(ytr_chords)):\n","#     for j in range(0, len(ytr_chords[i])):\n","#         Xtr_melody_pad[i] = np.vstack((padding,ytr_chords[i][:-1]))\n","\n","# print(Xtr_melody_pad.shape)\n","# print(Xtr_melody_pad[0].shape)"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"mCyVF9ryGCfk","colab_type":"code","colab":{}},"cell_type":"code","source":["print(Xtr_melody_pad[0][0])\n","print(Xtr_melody_pad[0][65])"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"KGGCxkjYnkVk"},"cell_type":"markdown","source":["# **Model Setup**"]},{"metadata":{"colab_type":"code","id":"Tq-MN5h4nuAY","trusted":true,"colab":{}},"cell_type":"code","source":["from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","from keras.utils.vis_utils import plot_model"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"8DqK7cspzx4v","trusted":true,"colab":{}},"cell_type":"code","source":["num_classes = 7\n","note_shift = 24\n","num_of_notes = 83\n","num_measures = 0.25\n","\n","tpqn = 96 # Varies with MIDI file, currently using same resolution\n","\n","n_timesteps= int(4*num_measures*tpqn) # 96 ticks per quarter note x 4 quarter notes per measure x number of measures\n","\n","batchsize = 5\n","\n","# configure\n","num_encoder_tokens = num_of_notes # length of the sequence at each time step = num of notes\n","num_decoder_tokens = num_of_notes\n","latent_dim = 256"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JvVisxnYGCfz","colab_type":"text"},"cell_type":"markdown","source":["**Autoencoder Model**"]},{"metadata":{"colab_type":"code","id":"vZD5nprYxdPL","trusted":true,"colab":{}},"cell_type":"code","source":["# Define an input sequence and process it.\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","autoencoder = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","autoencoder.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"ziVgGwmEGCf_","colab_type":"code","colab":{}},"cell_type":"code","source":["autoencoder.summary()\n","\n","# plot the model and save as image\n","# plot_model(autoencoder, to_file='model.png', show_shapes=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0agPg27OGCgF","colab_type":"text"},"cell_type":"markdown","source":["**Encoder Inference Model**"]},{"metadata":{"trusted":true,"id":"XJhxeLdIGCgG","colab_type":"code","colab":{}},"cell_type":"code","source":["# define encoder inference model\n","encoder_model = Model(encoder_inputs, encoder_states)"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"cX1WE0FkGCgJ","colab_type":"code","colab":{}},"cell_type":"code","source":["encoder_model.summary()\n","\n","# plot_model(encoder_model, to_file='encoder_model.png', show_shapes=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0JP7OzF9GCgM","colab_type":"text"},"cell_type":"markdown","source":["**Decoder Inference Model**"]},{"metadata":{"trusted":true,"id":"zvX5sfcjGCgN","colab_type":"code","colab":{}},"cell_type":"code","source":["# define decoder inference model\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"2LBWLVbEGCgQ","colab_type":"code","colab":{}},"cell_type":"code","source":["decoder_model.summary()\n","\n","# plot_model(decoder_model, to_file='decoder_model.png', show_shapes=True)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"ob0qW7XMxjmu"},"cell_type":"markdown","source":["## Training"]},{"metadata":{"colab_type":"code","id":"cL71g5kWkGtq","trusted":true,"colab":{}},"cell_type":"code","source":["hist_chords = autoencoder.fit([Xtr_melody, Xtr_melody_pad], ytr_chords, batch_size=batchsize, epochs=30, verbose=2)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"_1muwe5UxwL2"},"cell_type":"markdown","source":["## Testing\n","\n","Predictions are done using the inferences encoder and decoder models"]},{"metadata":{"colab_type":"code","id":"yoUWS7-GxyK7","trusted":true,"colab":{}},"cell_type":"code","source":["# generate target given source sequence\n","def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n","    # encode\n","    state = infenc.predict(source)\n","    \n","    # start of sequence input\n","    target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n","\n","    # collect predictions\n","    output = list()\n","    for t in range(n_steps):\n","        # predict next note\n","        yhat, h, c = infdec.predict([target_seq] + state)\n","        \n","        # store prediction\n","        output.append(yhat[0,0,:])\n","       \n","        # update state\n","        state = [h, c]\n","        \n","        # update target sequence\n","        target_seq = yhat\n","        \n","    return (np.array(output)).reshape(n_steps,cardinality)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"g5A7IaaMzU6c","trusted":true,"colab":{}},"cell_type":"code","source":["test_phrase = np.empty((1,n_timesteps, num_of_notes))\n","ypred_chords = np.empty((yts_chords.shape))\n","\n","for i in range(0, len(Xts_melody)):\n","    test_phrase[0] = Xts_melody[i]\n","    ypred_chords[i] = predict_sequence(encoder_model, decoder_model, test_phrase, n_timesteps, num_of_notes)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"M_NJg4evmhAu"},"cell_type":"markdown","source":["# Saving Results"]},{"metadata":{"colab_type":"code","id":"ghoc0HJwiXUD","trusted":true,"colab":{}},"cell_type":"code","source":["# Save the predicted values for post processing\n","os.chdir('../working/')\n","\n","np.save('../working/Xts_chords', Xts_melody)\n","np.save('../working/ypred_chords', ypred_chords)\n","np.save('../working/yts_chords', yts_chords)\n","\n","# Save the model for future use\n","\n","autoencoder.save('../working/chords_model.h5')\n","encoder_model.save('../working/chords_encoder.h5')\n","decoder_model.save('../working/chords_decoder.h5')"],"execution_count":0,"outputs":[]}]}